# -*- coding: utf-8 -*-
"""Crime Prediction-Neural Network

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lwH8B8SqJvvSY6jPesEGP2nfidH7A4gX
"""

#Import required libraries
import numpy as np  #To work with arrays
import pandas as pd #To work with dataframes
import matplotlib.pyplot as plt #plotting library
import seaborn as sns #plotting library
import tensorflow as tf #symbolic math library that allows complex machine learning algorithms and controls the dataflow across a range of tasks
import keras #Neural network library and works as a wrapper to low level library like tensorflow
from keras.models import Sequential #is used to create linear stacked layers
from keras.layers import Dense #Dense implements the operation for the activation in consideration
from sklearn.model_selection import train_test_split #split the dataset in to train and test
from sklearn.preprocessing import  MinMaxScaler #for normalization of data
from sklearn import metrics #to evaluate the model
from sklearn.metrics import r2_score #metrics to evaluate the accuracy of the regression model
from sklearn.metrics import mean_absolute_error, mean_squared_error #metrics to evaluate the error rate in the model
from sklearn.metrics import explained_variance_score #variance explained by the predictors for predicting target variable (a value of 1 indicates perfect prediction)
import warnings #to control the warnings displayed during run time
warnings.filterwarnings('ignore') #supresses the warning messages if any
sns.set(style='white', context='notebook', palette='deep', font_scale=1) 
from keras.layers import Dropout
from keras.callbacks import EarlyStopping
#The base context is “notebook”, and the other contexts are “paper”, “talk”, and “poster”, which are version of the notebook parameters scaled by .8, 1.3, and 1.6, respectively.
#deep, muted, bright, pastel, dark, colorblind are the available sns palettes based on which the plots will be displayed
#darkgrid, whitegrid, dark, white, ticks are the axes styles within sns

from google.colab import files #to import files in google colab
uploaded = files.upload() #upload files in google colab

narcotics = pd.read_csv('CrimeMerged.csv') #read the uploaded file
best = narcotics[['geohash', 'Primary_Type', 'Year', 'Month', 'WEEKDAY', 'Holiday',
                     'Time', 'crimescount','Avg_Student_Attendance_Rate', 'Avg_Teacher_Attendance_Rate', 'Mobility_Rate_Pct', 'NearestPoliceDist', 'NearestRedCamDist',
                      'RedCamCount', 'SchoolCount', 'avgTemp', 'prcp','wind']]

best.dtypes #verify the datatypes of the loaded file

#convert the categorical features to object data type
best.Month = best.Month.astype(object)
best.geohash = best.geohash.astype(object)
best.Year = best.Year.astype(object)
best.WEEKDAY = best.WEEKDAY.astype(object) 
best.Holiday = best.Holiday.astype(object)
best.Time = best.Time.astype(object)

best.describe() #verify the summary of the variables

best.columns #to display the columns of the dataframe

best_df_with_dummies = pd.get_dummies(best)
best_df_with_dummies.head(1)  #86 features with geohash,crime type, year, month and weekday, holiday

#Separate the predictors and target variables
x = best_df_with_dummies.drop(['crimescount'],axis=1).values
y = best_df_with_dummies.crimescount.values 
#Set the seed to generate the same random state
np.random.seed(18)

#Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(x, y,random_state = 10,test_size=0.20)
#test size: 80:20 split in this case
#random state: to generate the same split everytime

#Normalize only independent numerical variables
X_train[:,1] = X_train[:,1] / X_train[:,1].max()
X_train[:,2] = X_train[:,2] / X_train[:,2].max()
X_train[:,3] = X_train[:,3] / X_train[:,3].max()
X_train[:,4] = X_train[:,4] / X_train[:,4].max()
X_train[:,5] = X_train[:,5] / X_train[:,5].max()
X_train[:,6] = X_train[:,6] / X_train[:,6].max()
X_train[:,7] = X_train[:,7] / X_train[:,7].max()
X_train[:,8] = X_train[:,8] / X_train[:,8].max()
X_train[:,9] = X_train[:,9] / X_train[:,9].max()
X_train[:,10] = X_train[:,10] / X_train[:,10].max()

X_test[:,1] = X_test[:,1] / X_test[:,1].max()
X_test[:,2] = X_test[:,2] / X_test[:,2].max()
X_test[:,3] = X_test[:,3] / X_test[:,3].max()
X_test[:,4] = X_test[:,4] / X_test[:,4].max()
X_test[:,5] = X_test[:,5] / X_test[:,5].max()
X_test[:,6] = X_test[:,6] / X_test[:,6].max()
X_test[:,7] = X_test[:,7] / X_test[:,7].max()
X_test[:,8] = X_test[:,8] / X_test[:,8].max()
X_test[:,9] = X_test[:,9] / X_test[:,9].max()
X_test[:,10] = X_test[:,10] / X_test[:,10].max()
#Define ann layers
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
model.compile(loss='mse', optimizer='rmsprop', metrics=['mse'])
model.summary()
#fit the ann model
history = model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=2, validation_split=.2)
#plot loss vs. epoch curve
plt.figure(figsize=(10,5))
plt.plot(history.history['loss'],marker='o',color='orange')
plt.plot(history.history['val_loss'],marker='^',color='blue')
plt.title('Value Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()
#plot the train vs test mse
plt.figure(figsize=(10,5))
plt.plot(history.history['mean_squared_error'],marker='o',color='red')
plt.plot(history.history['val_mean_squared_error'],marker='^',color = 'green')
plt.title('Value Mean Squared Error')
plt.ylabel('MSE')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()
#predict test data with ann
pred_crimes = model.predict(X_test)
mse_pred_score = metrics.mean_squared_error(pred_crimes, y_test)
print('mse_pred_score {}'.format(mse_pred_score))
rmse_pred_score = np.sqrt(mse_pred_score)
print('rmse_pred_score {}'.format(rmse_pred_score))
r2_pred_score = r2_score(y_test, pred_crimes, multioutput='uniform_average')  
print('r2_pred_score - Coefficient of Determination {}'.format(r2_pred_score))
print("MAE ", mean_absolute_error(y_test, pred_crimes))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib
matplotlib.rc('xtick', labelsize=15) 
matplotlib.rc('ytick', labelsize=15) 
fig, ax = plt.subplots(figsize=(7, 5))
plt.style.use('ggplot')
plt.plot(pred_crimes, y_test, 'ro')
plt.xlabel('Predicted Crime Count', fontsize = 17)
plt.ylabel('Actual Crime Count', fontsize = 17)
plt.title('Predicted vs. Actual values', fontsize = 15)
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.show()

"""Add More layers and test"""
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))
model.add(Dense(64, kernel_initializer='he_uniform', activation='relu'))
model.add(Dense(32, kernel_initializer='he_uniform', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
model.compile(loss='mse', optimizer='rmsprop', metrics=['mse'])
model.summary()
#Set seed and fit the model
np.random.seed(80)
history = model.fit(X_train, y_train, batch_size=128, epochs=50, validation_split=.2, verbose=2)
plt.figure(figsize=(10,5))#Plot loss vs. epoch
plt.plot(history.history['loss'],marker='o',color='orange')
plt.plot(history.history['val_loss'],marker='^',color='blue')
plt.title('Value Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()
#plot the train vs test mse
plt.figure(figsize=(10,5))
plt.plot(history.history['mean_squared_error'],marker='o',color='red')
plt.plot(history.history['val_mean_squared_error'],marker='^',color = 'green')
plt.title('Value Mean Squared Error')
plt.ylabel('MSE')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()
pred_crimes = model.predict(X_test) #Predict crime count
mse_pred_score = metrics.mean_squared_error(pred_crimes, y_test)
print('mse_pred_score {}'.format(mse_pred_score))
rmse_pred_score = np.sqrt(mse_pred_score)
print('rmse_pred_score {}'.format(rmse_pred_score))
r2_pred_score = r2_score(y_test, pred_crimes, multioutput='uniform_average')  
print('r2_pred_score - Coefficient of Determination {}'.format(r2_pred_score))
print("MAE ", mean_absolute_error(y_test, pred_crimes))

#mse_pred_score 7.601609533841023
#rmse_pred_score 2.7571016546077916
#r2_pred_score - Coefficient of Determination 0.8467620603610193
#MAE  1.6603343160660669

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib

matplotlib.rc('xtick', labelsize=15) 
matplotlib.rc('ytick', labelsize=15) 
fig, ax = plt.subplots(figsize=(7, 5))
plt.style.use('ggplot')
plt.plot(pred_crimes, y_test, 'ro')
plt.xlabel('Predicted Crime Count', fontsize = 17)
plt.ylabel('Actual Crime Count', fontsize = 17)
plt.title('Predicted vs. Actual values', fontsize = 15)
ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)
plt.show()