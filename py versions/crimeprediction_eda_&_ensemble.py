# -*- coding: utf-8 -*-
"""CrimePrediction-EDA & Ensemble

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fV3b-fuNI2gk87k6P0fnjNeVfRKqMUuG
"""

#Import Libraries
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
#Import data preprocessing, data split, metrics libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error,explained_variance_score
#import ensemble learners
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgbo
#import cross validation libraries
from sklearn import model_selection
from sklearn.model_selection import KFold
#Import statistical libraries to plot distribution of data
from scipy import stats
from scipy.stats import norm, skew
#import warnings to supress if any
import warnings
warnings.filterwarnings('ignore')
#Common settings for sns plots
sns.set(style='white', context='notebook', palette='deep',font_scale=1)
#import files to colab
from google.colab import files

uploaded = files.upload()

crime = pd.read_csv('CrimeMerged.csv')
crime.shape #(33565, 28)
crime.dtypes
#Convert all categories to object datatype
crime.Year = crime.Year.astype(object)
crime.Month = crime.Month.astype(object)
crime.WEEKDAY = crime.WEEKDAY.astype(object)
crime.Holiday = crime.Holiday.astype(object) 
crime = crime.drop(columns='Day') # Drop unwanted column
crime.isna().sum() #Check for NA values

crime.dtypes

crime.head()

crime.Year.value_counts()

narcotics = crime.copy()

#We will plot our dependent variable, crime rate for its distribution and outliers
sns.set(font_scale=1)
narcotics['crimescount'].plot(kind='hist')
plt.show() #Right skewed which means positively skewed
narcotics.boxplot(column=['crimescount'],return_type='axes')
#we will check whether log transformation changes the skewness

#After log transformation, check the distribution
narcotics['crimelog'] = np.log1p(narcotics['crimescount'])
narcotics['crimelog'].plot(kind='hist')
plt.show() #Right skewed which means positively skewed
narcotics.boxplot(column=['crimelog'],return_type='axes')
#Even after log transformation, not much of a change
#Since ensemble learners RF & XGB do not carry any assumption about distribution, we will use the original crime count variable

narcotics.head()

#Defining plots for multiple visualizations
def multiplot(data,features,plottype,nrows,ncols,figsize,y=None,colorize=False):
    """ This function draw a multi plot for 3 types of plots ["regplot","distplot","coutplot"]"""
    n = 0
    plt.figure(1)
    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)
    
    if colorize:
        colors = sns.color_palette(n_colors=(nrows*ncols))
    else :
        colors = [None]*(nrows*ncols)
        
    for row in range(ncols):
        for col in range(nrows):
            
            if plottype == 'regplot':
                if y == None:
                    raise ValueError('y value is needed with regplot type')
                
                sns.regplot(data = data, x = features[n], y = y ,ax=axes[row,col], color = colors[n])
                correlation = np.corrcoef(data[features[n]],data[y])[0,1]
                axes[row,col].set_title("Correlation {:.2f}".format(correlation))
            
            elif plottype == 'distplot':
                sns.distplot(a = data[features[n]],ax = axes[row,col],color=colors[n])
                skewness = data[features[n]].skew()
                axes[row,col].legend(["Skew : {:.2f}".format(skewness)])
            
            elif plottype in ['countplot']:
                g = sns.countplot(x = data[features[n]], y = y, ax = axes[row,col],color = colors[n])
                g = plt.setp(g.get_xticklabels(), rotation=45)
                
            n += 1
    plt.tight_layout()
    plt.show()
    plt.gcf().clear()

#Check correlations
narcotics.corr()
sns.set(font_scale=1)
g = sns.heatmap(narcotics.corr())

#Data shows weak linear correlation 
narcotics_new = narcotics.drop(columns='crimelog')
corrmat =narcotics_new.corr()
#Display variables having correlation value above 0.15
top_corr_features = corrmat.index[abs(corrmat["crimescount"])>0.15]
g = sns.heatmap(narcotics_new[top_corr_features].corr(),annot=True,cmap="Blues",annot_kws={"color": 'black'})

#We will use the log scale to plot the factor plots
g = sns.factorplot(x="SpeedCamCount",y="crimelog",data=narcotics,kind='box',aspect=2.5)

g = sns.factorplot(x="WEEKDAY",y="crimelog",data=narcotics,kind='box',aspect=2)
#Shows weekend has more crime count

g = sns.factorplot(x="Month",y="crimelog",data=narcotics,kind='box',aspect=2)
#High in first quarter

g = sns.factorplot(x="Time",y="crimelog",data=narcotics,kind='box',aspect=2.5)
#High in evening and afternoon compared to morning and night

g = sns.jointplot(x = narcotics['SchoolCount'], y = narcotics['crimescount'],kind="reg")

#sns.pairplot(narcotics) #takes a lot of time, hence commented

g = sns.distplot(narcotics['crimescount'],color="red")
g = g.legend(['Skewness : {:.2f}'.format(narcotics['crimescount'].skew())],loc='best')
#Distribution in the form of distribution plot using sns

narcotics.columns

feats = ['NearestPoliceDist', 'NearestSpeedCamDist', 'NearestRedCamDist',
       'SpeedCamCount', 'RedCamCount']

multiplot(data = narcotics,features = feats,plottype = "regplot",nrows = 2, ncols = 2,
          figsize = (10,6),y = "crimescount", colorize = True)

feats = ['Avg_Misconduct_Rate',
       'Avg_Suspension_Rate', 'Avg_Student_Attendance_Rate',
       'Avg_Teacher_Attendance_Rate', 'Avg_Suspension_Days', 'SchoolCount',
       'Avg_Dropout_Rate', 'Avg_FreshmanTrack_Rate',
       'Avg_CollegeEnrollment_Rate', 'Avg_College_Persistence_Rate',
       'Mobility_Rate_Pct']

multiplot(data = narcotics,features = feats,plottype = "regplot",nrows = 3, ncols = 3,
          figsize = (10,6),y = "crimescount", colorize = True)

#all features skewness check
features = [ 'NearestPoliceDist', 'NearestSpeedCamDist', 'NearestRedCamDist',
       'SpeedCamCount', 'RedCamCount', 'Avg_Misconduct_Rate',
       'Avg_Suspension_Rate', 'Avg_Student_Attendance_Rate',
       'Avg_Teacher_Attendance_Rate', 'Avg_Suspension_Days', 'SchoolCount',
       'Avg_Dropout_Rate', 'Avg_FreshmanTrack_Rate',
       'Avg_CollegeEnrollment_Rate', 'Avg_College_Persistence_Rate',
       'Mobility_Rate_Pct']
multiplot(data = narcotics,features = features,plottype = "distplot",
          nrows = 4, ncols = 4, figsize = (11,9), colorize = True)

plt.figure(1)
fig, axes = plt.subplots(1,2,figsize=(15,7))

sns.distplot(narcotics["crimescount"],ax = axes[0])
sns.distplot(np.log1p(narcotics["crimescount"]),ax = axes[1],color="g")

axes[0].legend(["Skew : {:.2f}".format(narcotics["crimescount"].skew())])
axes[1].legend(["Skew : {:.2f}".format(np.log1p(narcotics["crimescount"].skew()))])

plt.tight_layout()
plt.show()
plt.gcf().clear()

"""Without Feature Selection"""

narcotics = narcotics.drop(columns='crimelog')
narcotics_dummies = pd.get_dummies(narcotics)
narcotics_dummies.head() #95 columns

model_data = narcotics_dummies.values
X = model_data[:,1:]
Y = model_data[:,0]
np.random.seed(67)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=70)

#list(narcotics_dummies.columns) (Big output cell)

#Random Forest for feature selection on data without feature selection
feat_labels = ['NearestPoliceDist',
 'NearestSpeedCamDist','NearestRedCamDist','SpeedCamCount','RedCamCount','Avg_Misconduct_Rate','Avg_Suspension_Rate','Avg_Student_Attendance_Rate',
 'Avg_Teacher_Attendance_Rate','Avg_Suspension_Days','SchoolCount','Avg_Dropout_Rate','Avg_FreshmanTrack_Rate','Avg_CollegeEnrollment_Rate','Avg_College_Persistence_Rate',
 'Mobility_Rate_Pct','avgTemp','prcp','wind',
 'geohash_dp3sy','geohash_dp3sz','geohash_dp3t5','geohash_dp3t7','geohash_dp3td','geohash_dp3te',
 'geohash_dp3tf','geohash_dp3tg','geohash_dp3th','geohash_dp3tj','geohash_dp3tk','geohash_dp3tm',
 'geohash_dp3tn','geohash_dp3tp','geohash_dp3tq','geohash_dp3tr','geohash_dp3ts','geohash_dp3tt',
 'geohash_dp3tu','geohash_dp3tv','geohash_dp3tw','geohash_dp3tx','geohash_dp3ty','geohash_dp3v0',
 'geohash_dp3v2','geohash_dp3w4','geohash_dp3w5','geohash_dp3w6','geohash_dp3w7','geohash_dp3w9',
 'geohash_dp3wc','geohash_dp3wd','geohash_dp3we','geohash_dp3wf','geohash_dp3wg','geohash_dp3wh',
 'geohash_dp3wj','geohash_dp3wk','geohash_dp3wm','geohash_dp3wn','geohash_dp3wq','geohash_dp3ws',
 'geohash_dp3wt','geohash_dp3wu','geohash_dp3wv','geohash_dp3x1','geohash_dp3xh',
 'Primary_Type_ASSAULT','Primary_Type_HOMICIDE','Primary_Type_NARCOTICS','Primary_Type_VIOLATIONS','Year_2015','Year_2016','Year_2017','Year_2018',
 'Month_1','Month_2','Month_3','Month_4','Month_5','Month_6','Month_7','Month_8','Month_9','Month_10','Month_11','Month_12','WEEKDAY_0','WEEKDAY_1','Holiday_False','Holiday_True',
 'Time_afternoon','Time_evening','Time_morning','Time_night']
clf = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
# Train the classifier
clf.fit(X_train, Y_train)

y_pred = clf.predict(X_test)
# View The Accuracy Of all features (95 Features) Model
print("Variance Score is", explained_variance_score(y_pred,Y_test))
print('R2:',clf.score(X_test,Y_test))
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))

#XGBoost
xgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
xgb.fit(X_train,Y_train)
predictions = xgb.predict(X_test)
print("Variance Score is", explained_variance_score(predictions,Y_test))
print("R2 ",r2_score(Y_test, predictions))
print("MAE ", mean_absolute_error(Y_test, predictions))
print("MSE ",mean_squared_error(Y_test,predictions))
print("RMSE is",np.sqrt(mean_squared_error(Y_test,predictions)))

"""Top 20 features"""

X = narcotics_dummies.drop('crimescount',axis=1)
Y = narcotics_dummies.crimescount
colnames = narcotics_dummies.columns

from sklearn.preprocessing import MinMaxScaler
ranks = {}
# Create our function which stores the feature rankings to the ranks dictionary
def ranking(ranks, names, order=1):
    minmax = MinMaxScaler()
    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]
    ranks = map(lambda x: round(x,2), ranks)
    return dict(zip(names, ranks))

# Construct our Random Forest Regression model
from sklearn.feature_selection import RFE
rr = RandomForestRegressor()
rr.fit(X,Y)
#stop the search when only the last feature is left
rfe = RFE(rr, n_features_to_select=20, verbose =3 )
rfe.fit(X,Y)
ranks["RFE_pub"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)
print(ranks)

#Top 20 best features selected by random forest with categorical one hot encoded features
#Note that there is a significant loss of categorical features with this approach
#NearestPoliceDist,NearestRedCamDist,Avg_Student_Attendance_Rate,Avg_Teacher_Attendance_Rate,SchoolCount,Avg_FreshmanTrack_Rate,Mobility_Rate_Pct,avgTemp,prcp,wind
best_rf_20 = narcotics_dummies[['crimescount','Avg_College_Persistence_Rate','Avg_Student_Attendance_Rate','Avg_Suspension_Days','Avg_Suspension_Rate',
  'Holiday_True','Mobility_Rate_Pct','Month_12','NearestSpeedCamDist','Primary_Type_ASSAULT','Primary_Type_HOMICIDE','Primary_Type_NARCOTICS',
  'RedCamCount','SchoolCount','Time_afternoon','Time_morning','WEEKDAY_0','avgTemp','geohash_dp3xh','prcp']]

best_rf_20.shape

best_rf_20.head() #20 columns

model_data = best_rf_20.values
X = model_data[:,1:]
Y = model_data[:,0]
np.random.seed(80)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=20)

feat_labels = [
 'Avg_College_Persistence_Rate','Avg_Student_Attendance_Rate','Avg_Suspension_Days','Avg_Suspension_Rate',
  'Holiday_True','Mobility_Rate_Pct','Month_12','NearestSpeedCamDist','Primary_Type_ASSAULT','Primary_Type_HOMICIDE','Primary_Type_NARCOTICS',
  'RedCamCount','SchoolCount','Time_afternoon','Time_morning','WEEKDAY_0','avgTemp','geohash_dp3xh','prcp'      ]
clf = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
# Train the classifier
clf.fit(X_train, Y_train)

y_pred = clf.predict(X_test)
# View The Accuracy Of best features (20 Features) Model
print("Variance Score is", explained_variance_score(y_pred,Y_test))
print('R2 is',clf.score(X_test,Y_test))
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))

#XGBoost with best 20 features
xgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
xgb.fit(X_train,Y_train)
predictions = xgb.predict(X_test)
print("Variance Score is", explained_variance_score(predictions,Y_test))
print("R2 ",r2_score(Y_test, predictions))
print("MAE ", mean_absolute_error(Y_test, predictions))
print("MSE ",mean_squared_error(Y_test,predictions))
print("RMSE is",np.sqrt(mean_squared_error(Y_test,predictions)))

#Extract only numeric columns
narcotics_num = narcotics.select_dtypes(include=['int64','float64'])
crime = narcotics_num.drop(['crimescount'], axis=1)
X = crime.as_matrix()
Y = narcotics_num.crimescount.values
colnames = crime.columns

# Construct our Random Forest Regression model
from sklearn.feature_selection import RFE
rr = RandomForestRegressor()
rr.fit(X,Y)
#stop the search when only the last feature is left
rfe = RFE(rr, n_features_to_select=10, verbose =3 )
rfe.fit(X,Y)
ranks["RFE_pub"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)
ranks

#Top 10 numeric features and encoded categorical features
best_rf = narcotics[['geohash', 'Primary_Type', 'Year', 'Month', 'WEEKDAY', 'Holiday',
                     'Time', 'crimescount','Avg_Student_Attendance_Rate', 'Avg_Teacher_Attendance_Rate', 'Mobility_Rate_Pct', 'NearestPoliceDist', 'NearestRedCamDist',
                     'Time', 'crimescount','Avg_Student_Attendance_Rate', 'Avg_Teacher_Attendance_Rate', 'Mobility_Rate_Pct', 'NearestPoliceDist', 'NearestRedCamDist',
                      'RedCamCount', 'SchoolCount', 'avgTemp', 'prcp','wind']]

best_rf_dummies = pd.get_dummies(best_rf)
best_rf_dummies.head() #86 columns
#list(best_rf_dummies.columns) (Big output cell)
model_data = best_rf_dummies.values
#separate target and independent variables
X = model_data[:,1:]
Y = model_data[:,0]
#Set seed
np.random.seed(80)
#Split train and test data in 80:20 ratio
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=20)

feat_labels = [
  'Avg_Student_Attendance_Rate','Avg_Teacher_Attendance_Rate','Mobility_Rate_Pct','NearestPoliceDist','NearestRedCamDist',
 'RedCamCount','SchoolCount','avgTemp','prcp','wind',
 'geohash_dp3sy','geohash_dp3sz','geohash_dp3t5','geohash_dp3t7','geohash_dp3td','geohash_dp3te','geohash_dp3tf','geohash_dp3tg',
 'geohash_dp3th','geohash_dp3tj','geohash_dp3tk','geohash_dp3tm','geohash_dp3tn','geohash_dp3tp','geohash_dp3tq','geohash_dp3tr',
 'geohash_dp3ts','geohash_dp3tt','geohash_dp3tu','geohash_dp3tv','geohash_dp3tw','geohash_dp3tx','geohash_dp3ty','geohash_dp3v0',
 'geohash_dp3v2','geohash_dp3w4','geohash_dp3w5','geohash_dp3w6','geohash_dp3w7','geohash_dp3w9','geohash_dp3wc','geohash_dp3wd',
 'geohash_dp3we','geohash_dp3wf','geohash_dp3wg','geohash_dp3wh','geohash_dp3wj','geohash_dp3wk','geohash_dp3wm','geohash_dp3wn',
 'geohash_dp3wq','geohash_dp3ws','geohash_dp3wt','geohash_dp3wu','geohash_dp3wv','geohash_dp3x1','geohash_dp3xh',
 'Primary_Type_ASSAULT','Primary_Type_HOMICIDE','Primary_Type_NARCOTICS','Primary_Type_VIOLATIONS',
 'Year_2015','Year_2016','Year_2017','Year_2018','Month_1','Month_2','Month_3','Month_4','Month_5','Month_6','Month_7','Month_8','Month_9','Month_10','Month_11','Month_12',
 'WEEKDAY_0','WEEKDAY_1','Holiday_False','Holiday_True','Time_afternoon','Time_evening','Time_morning','Time_night']
clf = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
# Train the classifier
clf.fit(X_train, Y_train)
#Training model accuracy
trainac = clf.predict(X_train)
print("Train accuracy details of Random Forest")
print("RMSE is",np.sqrt(mean_squared_error(Y_train,trainac))) 
print("R2 ",r2_score(Y_train, trainac))
print("MAE ", mean_absolute_error(Y_train, trainac))
print("MSE ",mean_squared_error(Y_train,trainac))
#Testing model accuracy
y_pred = clf.predict(X_test)
# View The Accuracy Of best features (20 Features) Model
print(clf.score(X_test,Y_test))
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))
#0.8454092242539049

#XGBoost
xgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
xgb.fit(X_train,Y_train)
predictions = xgb.predict(X_test)
print("Variance Score is", explained_variance_score(predictions,Y_test))
print("R2 ",r2_score(Y_test, predictions))
print("MAE ", mean_absolute_error(Y_test, predictions))
print("MSE ",mean_squared_error(Y_test,predictions))
print("RMSE is",np.sqrt(mean_squared_error(Y_test,predictions)))
trainac = xgb.predict(X_train)
print("Train accuracy details on the tuned - XGBoost")
print("RMSE is",np.sqrt(mean_squared_error(Y_train,trainac))) 
print("R2 ",r2_score(Y_train, trainac))
print("MAE ", mean_absolute_error(Y_train, trainac))
print("MSE ",mean_squared_error(Y_train,trainac))

#Random Forest
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=3, random_state=200, shuffle=True)
model_kfoldrand = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
#scores = cross_val_score(clfrffive, X_trainkf, y_trainkf, cv=10, scoring='neg_mean_absolute_error')
#print(scores)
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
clfrfthree = model_kfoldrand.fit(X_trainkf, y_trainkf)
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

#Random Forest
kfold = model_selection.KFold(n_splits=5, random_state=200,shuffle=True)
model_kfoldrand = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
clfrffive = model_kfoldrand.fit(X_trainkf, y_trainkf)
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

# Commented out IPython magic to ensure Python compatibility.
#Random Forest
kfold = model_selection.KFold(n_splits=10, random_state=200,shuffle=True)
model_kfoldrand = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfrften = model_kfoldrand.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldrand.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Explained Variance score: %.2f' % model_kfoldrand.score(X_testkf, y_testkf))
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

# Commented out IPython magic to ensure Python compatibility.
#Random Forest
kfold = model_selection.KFold(n_splits=20, random_state=200,shuffle=True)
model_kfoldrand = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfrftwenty = model_kfoldrand.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldrand.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Explained Variance score: %.2f' % model_kfoldrand.score(X_testkf, y_testkf))
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

# Commented out IPython magic to ensure Python compatibility.
#Random Forest
kfold = model_selection.KFold(n_splits=30, random_state=200,shuffle=True)
model_kfoldrand = RandomForestRegressor(n_estimators=10, random_state=20, n_jobs=-1)
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfrfthirty = model_kfoldrand.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldrand.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Explained Variance score: %.2f' % model_kfoldrand.score(X_testkf, y_testkf))
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=3, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=5, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=10, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=20, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=30, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(n_estimators=100, learning_rate=0.1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))

#Hyper parameters for Random Forest
from sklearn.model_selection import RandomizedSearchCV
# Number of trees in random forest
n_estimators = [int(x) for x in np.linspace(start = 10, stop = 500, num = 5)]
# Number of features to consider at every split
max_features = ['auto', 'sqrt']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]
max_depth.append(None)
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4]
# Method of selecting samples for training each tree
bootstrap = [True, False]
# Create the random grid
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
print(random_grid)
# Use the random grid to search for best hyperparameters
# First create the base model to tune
import datetime
print(datetime.datetime.now())
rf = RandomForestRegressor()
# Random search of parameters, using 10 fold cross validation, 
# search across 1000 different combinations, and use all available cores
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=20, n_jobs = -1)
# Fit the random search model
rf_random.fit(X_train, Y_train)

print(datetime.datetime.now())
#{'n_estimators': [10, 132, 255, 377, 500], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}
#https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74


"""2019-12-07 19:31:41.518156
Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.
[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.1min
[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 32.7min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 74.0min finished
2019-12-07 20:46:34.280382
"""

rf_random.best_params_
#'bootstrap': True,
#'max_depth': 50,
#'max_features': 'auto',
#'min_samples_leaf': 4,
#'min_samples_split': 5,
#'n_estimators': 377}

tuned_model = RandomForestRegressor(bootstrap= True,
 max_depth= 50,
 max_features= 'auto',
 min_samples_leaf= 4,
 min_samples_split= 5,
 n_estimators= 377, random_state = 20,n_jobs=-1)
 #Fit the tuned model
tuned_model.fit(X_train, Y_train)
trainac = tuned_model.predict(X_train)
#Train accuracy
print("Train accuracy details on the tuned of Random Forest")
print("RMSE is",np.sqrt(mean_squared_error(Y_train,trainac))) 
print("R2 ",r2_score(Y_train, trainac))
print("MAE ", mean_absolute_error(Y_train, trainac))
print("MSE ",mean_squared_error(Y_train,trainac))
#Predict crime count
y_pred = tuned_model.predict(X_test)
# View The Accuracy Of best features (86 Features) Model with tuned parameters
tuned_model.score(X_test,Y_test)
print("RMSE is",np.sqrt(mean_squared_error(Y_test,y_pred))) 
print("R2 ",r2_score(Y_test, y_pred))
print("MAE ", mean_absolute_error(Y_test, y_pred))
print("MSE ",mean_squared_error(Y_test,y_pred))

# Commented out IPython magic to ensure Python compatibility.
#Apply tuned parameters on 10 fold split data 
#Random Forest
kfold = model_selection.KFold(n_splits=10, random_state=200,shuffle=True)
model_kfoldrand = RandomForestRegressor(bootstrap= True,
 max_depth= 50,
 max_features= 'auto',
 min_samples_leaf=4,
 min_samples_split= 5,
 n_estimators= 377, random_state = 20,n_jobs=-1)
results_kfoldrand = model_selection.cross_val_score(model_kfoldrand, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldrand.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfrf = model_kfoldrand.fit(X_trainkf, y_trainkf)
#print('Coefficients: \n', model_kfoldreg.coef_)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldrand.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Explained Variance score: %.2f' % model_kfoldrand.score(X_testkf, y_testkf))
kfoldrf = model_kfoldrand.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldrf))) 
print("R2 ",r2_score(y_testkf, kfoldrf))
print("MAE ", mean_absolute_error(y_testkf, kfoldrf))
print("MSE ",mean_squared_error(y_testkf,kfoldrf))

trainac = model_kfoldrand.predict(X_trainkf)
print("Train accuracy details on the tuned - 10 fold model of Random Forest")
print("RMSE is",np.sqrt(mean_squared_error(y_trainkf,trainac))) 
print("R2 ",r2_score(y_trainkf, trainac))
print("MAE ", mean_absolute_error(y_trainkf, trainac))
print("MSE ",mean_squared_error(y_trainkf,trainac))

#Hyper parameters for XGBoost

# A parameter grid for XGBoost
params = {
        'learning_rate':[0.02,0.05,0.08,0.10],
        'n_estimators':[20,50,100,150,200],
        'min_child_weight': [1, 5, 10],
        'gamma': [0,0.5, 1, 1.5, 2],
        'subsample': [0.6, 0.75 ,0.8, 1.0],
        'colsample_bytree': [0.6, 0.8, 1.0],
        'max_depth': [3, 4, 5,7,8]
        }
xgb = xgbo.XGBRegressor()
xgbkf = model_selection.KFold(n_splits=10, random_state=200,shuffle=True)
random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=100, n_jobs=-1, 
cv=xgbkf.split(X,Y), verbose=3, random_state=20)
print(datetime.datetime.now())
random_search.fit(X, Y)
print(datetime.datetime.now())

"""2019-12-06 22:31:13.759389
Fitting 10 folds for each of 100 candidates, totalling 1000 fits
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.
[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.5min
[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  9.5min
[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 32.2min
[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 53.5min
[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 82.8min
[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 113.6min finished
[00:24:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.
2019-12-07 00:25:26.363527
"""

random_search.best_params_
#{'colsample_bytree': 1.0,
# 'gamma': 1.5,
# 'learning_rate': 0.05,
# 'max_depth': 8,
# 'min_child_weight': 10,
# 'n_estimators': 200,
# 'subsample': 0.75}

#Tuned model for XGB
tuned_modelxgb = xgbo.XGBRegressor(bootstrap= True,
 colsample_bytree= 1.0,
 gamma= 1.5,
 learning_rate= 0.05,
 max_depth= 8,
 min_child_weight= 10,
 n_estimators = 200,
 subsample= 0.75, random_state = 20,n_jobs=-1)
tuned_modelxgb.fit(X_train, Y_train)
trainac = tuned_modelxgb.predict(X_train)
print("Train accuracy details on the tuned - XGBoost")
print("RMSE is",np.sqrt(mean_squared_error(Y_train,trainac))) 
print("R2 ",r2_score(Y_train, trainac))
print("MAE ", mean_absolute_error(Y_train, trainac))
print("MSE ",mean_squared_error(Y_train,trainac))
y_pred = tuned_modelxgb.predict(X_test)
# View The Accuracy Of best features (86 Features) Model with tuned parameters
tuned_modelxgb.score(X_test,Y_test)
print("RMSE is",np.sqrt(mean_squared_error(Y_test,y_pred))) 
print("R2 ",r2_score(Y_test, y_pred))
print("MAE ", mean_absolute_error(Y_test, y_pred))
print("MSE ",mean_squared_error(Y_test,y_pred))

# Commented out IPython magic to ensure Python compatibility.
#kfold on xgboost tuned
from sklearn.model_selection import cross_val_score
kfold = model_selection.KFold(n_splits=10, random_state=200,shuffle=True)
model_kfoldxgb = xgbo.XGBRegressor(bootstrap= True,
 colsample_bytree= 1.0,
 gamma= 1.5,
 learning_rate= 0.05,
 max_depth= 8,
 min_child_weight= 10,
 n_estimators = 200,
 subsample= 0.75, random_state = 20,n_jobs=-1)
results_kfoldxgb = cross_val_score(model_kfoldxgb, X, Y, cv=kfold)
print("Accuracy: %.2f%%" % (results_kfoldxgb.mean()*100.0)) 
for train_index, test_index in kfold.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_trainkf, X_testkf = X[train_index], X[test_index]
    y_trainkf, y_testkf = Y[train_index], Y[test_index]
clfxgb = model_kfoldxgb.fit(X_trainkf, y_trainkf)
print("Residual sum of squares: %.2f"
#     % np.mean((model_kfoldxgb.predict(X_testkf) - y_testkf) ** 2))
#Explained variance score: 1 is perfect prediction
print('Variance score: %.2f' % model_kfoldxgb.score(X_testkf, y_testkf))
kfoldxgb = model_kfoldxgb.predict(X_testkf)
print("RMSE is",np.sqrt(mean_squared_error(y_testkf,kfoldxgb))) 
print("R2 ",r2_score(y_testkf, kfoldxgb))
print("MAE ", mean_absolute_error(y_testkf, kfoldxgb))
print("MSE ",mean_squared_error(y_testkf,kfoldxgb))
#Train accuracy
trainac = model_kfoldxgb.predict(X_trainkf)
print("RMSE is",np.sqrt(mean_squared_error(y_trainkf,trainac))) 
print("R2 ",r2_score(y_trainkf, trainac))
print("MAE ", mean_absolute_error(y_trainkf, trainac))
print("MSE ",mean_squared_error(y_trainkf,trainac))